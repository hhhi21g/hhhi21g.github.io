---
layout: post

title: 01_Repeated Padding for Sequential Recommendation

date: 2025-02-04 20:52:23 +0900

categories: [æ¨èç³»ç»Ÿ]
tags: [è®ºæ–‡é˜…è¯»]
---

- [é—®é¢˜çš„å¼•å‡º](#é—®é¢˜çš„å¼•å‡º)
- [é—®é¢˜ç¬¦å·åŒ–](#é—®é¢˜ç¬¦å·åŒ–)
- [ç›¸å…³çš„ç°æœ‰æŠ€æœ¯](#ç›¸å…³çš„ç°æœ‰æŠ€æœ¯)
- [RepPad](#reppad)
- [å®éªŒ](#å®éªŒ)
- [æ¶ˆèå®éªŒ](#æ¶ˆèå®éªŒablation-study)

æ¥æºï¼šRecSys'24  &nbsp; https://doi.org/10.1145/3640457.3688110

æ•°æ®é›†åŠä»£ç ï¼šhttps://github.com/KingGugu/RepPad

### é—®é¢˜çš„å¼•å‡º

- è®­ç»ƒè¿‡ç¨‹ï¼Œé•¿åºåˆ—è¢«æˆªæ–­ï¼ŒçŸ­åºåˆ—è¢«å¡«å……

- ç”±äºç”¨æˆ·ä¹ æƒ¯å’Œé•¿å°¾æ•ˆåº”ï¼Œåªæœ‰å°‘æ•°ç”¨æˆ·æœ‰é•¿çš„äº¤äº’åºåˆ—ï¼Œå¤§å¤šæ•°ç”¨æˆ·çš„äº¤äº’åºåˆ—éå¸¸çŸ­

- å½“å¡«å……ä¸€ä¸ªåºåˆ—ï¼Œ0ç»å¸¸è¢«ä½¿ç”¨ï¼Œå®ƒä¸åŒ…å«ä»»ä½•æœ‰æ„ä¹‰çš„ä¿¡æ¯å¹¶ä¸”ä¸è¢«åŒ…æ‹¬åœ¨æ¨¡å‹è®¡ç®—ï¼Œå¼•å‡ºé—®é¢˜ï¼š**æˆ‘ä»¬èƒ½å¦é€šè¿‡å¡«å……å…¶ä»–å†…å®¹æ¥åˆ©ç”¨è¿™ä¸ªç©ºé—²ç©ºé—´ä»¥è¿›ä¸€æ­¥æé«˜æ¨¡å‹è¡¨ç°å’Œè®­ç»ƒæ•ˆç‡ï¼Ÿ**

  > *Can we utilize this idle input space by padding other content to improve model performance and training efficiency further?*

æå‡ºä¸€ä¸ªå¡«å……ç­–ç•¥ï¼š**Rep**eated **Pad**ding  (**RepPad**)

------

### é—®é¢˜ç¬¦å·åŒ–

user sets: **ğ’°**

item sets: **ğ’±**

Each user uâˆˆ**ğ’°** is associated with *a sequence of interacted items* in chronological(æŒ‰æ—¶é—´å‰åé¡ºåºæ’åˆ—çš„) order s<sub>u</sub> = [v<sub>1</sub>,...,v<sub>j</sub>,...v<sub>\|s<sub>u</sub>\|</sub>]

- v<sub>j</sub> : user u ä¸è¯¥ç‰©ä½“äº¤äº’åœ¨æ—¶é—´æ­¥é•¿ä¸ºjæ—¶
- \|s<sub>u</sub>\| : åºåˆ—é•¿åº¦

ç»™å‡ºäº¤äº’ç‰©ä½“åºåˆ—\|s<sub>u</sub>\|, ä»»åŠ¡æ˜¯æ­£ç¡®çš„é¢„æµ‹: ç”¨æˆ·uåœ¨æ—¶é—´æ­¥é•¿ä¸º\|s<sub>u</sub>\|+1æ—¶æœ€å¯èƒ½äº¤äº’çš„ç‰©ä½“v<sup>*</sup>

> Given the sequences of interacted items *ğ‘ <sub>ğ‘¢</sub>* , our task is to accurately predict the most possible item *ğ‘£* âˆ— that user *ğ‘¢* will interact with at time step \|*ğ‘ <sub>ğ‘¢</sub>* \| + 1

<p>
    <img src="https://hhhi21g.github.io/assets/img/SR/a1.png" alt="alt text" style="zoom:50%;" />
</p>

------

### ç›¸å…³çš„ç°æœ‰æŠ€æœ¯

1. **Padding in Sequential Recommendation**

   <p>
       <img src="https://hhhi21g.github.io/assets/img/SR/a4.png" alt="alt text"/>
   </p>
   
   
   <p>
       <img src="https://hhhi21g.github.io/assets/img/SR/a5.png" alt="alt text" style="zoom:80%;" />
   </p>
   <p>
       <img src="https://hhhi21g.github.io/assets/img/SR/a0.png" alt="alt text" style="zoom:50%;" />
   </p>


   - ZeroPad(Â·) : padding the 0 to the left side of the sequence until its length is N

   - Intercept(Â·) : intercepting the nearest N interactions

   - s<sup>f</sup><sub>u</sub> : the final input to the model where \|s<sup>f</sup><sub>u</sub> \| = N

   - \|ğ’°\| : the total number of sequences involved in model training, one sequence for each user

   - N :  æœ€å¤§åºåˆ—é•¿åº¦

2. **Sequence Data Augmentation**

   <p>
       <img src="https://hhhi21g.github.io/assets/img/SR/a6.png" alt="alt text" style="zoom:80%;" />
   </p>
   <p>
       <img src="https://hhhi21g.github.io/assets/img/SR/a7.png" alt="alt text" style="zoom:80%;" />
   </p>
   
   
   
   - To alleviate the data sparsity problem
   
   - s<sup>d</sup><sub>u</sub> : the new sequence , ä¸ s<sub>u</sub>éƒ½ç”¨äºæ¨¡å‹è®­ç»ƒå’Œè‡ªæˆ‘ç›‘ç£å­¦ä¹ 
   
   - åœ¨æ¯ä¸€è½®ï¼Œæ¯ä¸ªåºåˆ—éƒ½å°†è¢«æ‰©å¼ è‡³å°‘ä¸€æ¬¡ï¼Œå› æ­¤åŒ…æ‹¬åœ¨æ¨¡å‹è®­ç»ƒä¸­çš„åºåˆ—æ•°ç›®è‡³å°‘ä¸º2\|ğ’°\|
   - åŸå§‹åºåˆ—å’Œå¢å¼ºåçš„åºåˆ—åŒæ ·éœ€è¦åº”ç”¨(2)å¼

------

### RepPad      

**åˆ©ç”¨åŸå§‹åºåˆ—ä½œä¸ºå¡«å……æ–‡æœ¬ï¼Œè€Œä¸æ˜¯0**

<p>
    <img src="https://hhhi21g.github.io/assets/img/SR/a8.png" alt="alt text" style="zoom:80%;" />
</p>

<p>
    <img src="https://hhhi21g.github.io/assets/img/SR/a2.png" alt="alt text" style="zoom:50%;" />
</p>


m :

-  å¡«å……æ¬¡æ•°

- can be pre-specified or calculated based on the original sequence length s<sub>u</sub> and the maximum sequence length N

\|  :  sequence concatenation,åºåˆ—å¹¶ç½®

<br/>

**problem: there may be cases where the end of the original sequence is used to predict the head**

<p>
    <img src="https://hhhi21g.github.io/assets/img/SR/a9.png" alt="alt text" style="zoom:80%;" />
</p>
<p>
    <img src="https://hhhi21g.github.io/assets/img/SR/a3.png" alt="alt text" style="zoom:50%;" />
</p>


<br/>

**ç‰¹ç‚¹**ï¼š

- æ²¡æœ‰å¯è®­ç»ƒçš„å‚æ•°æˆ–è¶…å‚æ•°

- æ˜¯ä¸€ç§ä¸æ¨¡å‹æ— å…³çš„å³æ’å³ç”¨çš„æ•°æ®å¢å¼ºæ–¹æ³•

  > It is a model-agnostic plug-and-play data augmentation approach

- ä¸å—ä¸»å¹²ç½‘ç»œçš„é™åˆ¶ï¼Œå¹¶å¯ä»¥æ— ç¼æ’å…¥åˆ°å¤§å¤šæ•°ç°æœ‰çš„åºåˆ—æ¨èæ¨¡å‹ä¸­

- ä½¿æ¨¡å‹èƒ½å¤Ÿå…¬å¹³çš„å…³æ³¨çŸ­åºåˆ—å’Œé•¿åºåˆ—ï¼Œæ›´å…³æ³¨é•¿å°¾é¡¹ç›®å’Œç”¨æˆ·ã€‚æ¨¡å‹å¯ä»¥æ›´å¥½çš„å­¦ä¹ å†·å¯åŠ¨ç”¨æˆ·å’Œé¡¹ç›®çš„è¡¨ç°ã€‚

- æ¨æµ‹ï¼Œèµ·åˆ°äº†æŸç§æ­£åˆ™åŒ–çš„ä½œç”¨ï¼Œå‡è½»äº†åŸå§‹æ•°æ®é›†åˆ†å¸ƒä¸å‡åŒ€çš„æ¶ˆæå½±å“

  > We also speculate that RepPad acts as some kind of regularization, which mitigates the negative effects of the uneven distribution of original dataset.

**Why RepPad works?**

- æŸå¤±æ”¶æ•›å’Œè®­ç»ƒæ•ˆç‡

  RepPadæŸå¤±æ”¶æ•›é€Ÿåº¦æ¯”åŸå§‹æ¨¡å‹ç•¥å¿«ï¼Œä¸”ä»…å¢åŠ äº†å°‘é‡è€—æ—¶

- æ¢¯åº¦ç¨³å®šæ€§

  æ¢¯åº¦ç¨³å®šæ€§ç ”ç©¶è¡¨æ˜ï¼Œæ›´ç¨³å®šæˆ–å¹³æ»‘çš„æ¢¯åº¦æ›´æœ‰åŠ©äºæ¨¡å‹è®­ç»ƒï¼›ä½¿ç”¨è¯¥æ–¹æ³•åï¼Œæ¢¯åº¦å€¼æ›´åŠ ç¨³å®š

**ä¸ç°æœ‰æ–¹æ³•çš„æ¯”è¾ƒ**ï¼š

1. ä¸ä¼šå¢åŠ åºåˆ—æ•°ç›®

2. æ²¡æœ‰è¶…å‚æ•°

3. æ— éœ€è®­ç»ƒæˆæœ¬ï¼Œä¸æ¨¡å‹æ— å…³

   > No Training Cost and Model Agnostic.

**å±€é™**ï¼š

Intuitively, å¯èƒ½æ˜¯æ— æ•ˆçš„åœ¨é•¿åºåˆ—æ•°æ®é›†ä¸Šï¼›

å› ä¸ºå¯¹äºé•¿åºåˆ—æ•°æ®é›†ï¼Œå¤§å¤šæ•°ä½¿ç”¨è€…çš„åºåˆ—é•¿åº¦æ¥è¿‘æˆ–è¶…è¿‡æ‰€ç»™çš„æœ€å¤§åºåˆ—é•¿åº¦,å°†æ²¡æœ‰ç©ºé—´ç•™ç»™å¡«å……ã€‚

------

### å®éªŒ

the baselines consisit of three main catagories:

1. å»è¯„ä»·RepPadæ˜¯å¦åœ¨æé«˜æ¨¡å‹çš„è¡¨ç°æ–¹é¢æ˜¯æœ‰æ•ˆçš„

2. è¢«å¹¿æ³›ä½¿ç”¨çš„éšæœºæ•°æ®å¢å¼ºæ–¹æ³•ï¼Œä¸éœ€è¦è®­ç»ƒä½†æ˜¯åŒ…æ‹¬ä¸€äº›éœ€è¦æ‰‹åŠ¨è°ƒä¼˜çš„è¶…å‚æ•°
3. è®­ç»ƒæ‰€éœ€çš„æ•°æ®å¢å¼ºæ¨¡å‹ä»£è¡¨ï¼Œé€šå¸¸åŒ…å«å¯è®­ç»ƒçš„å‚æ•°å’Œè¶…å‚æ•°

**è¯„ä»·æŒ‡æ ‡ï¼ˆEvaluation Metricsï¼‰**ï¼š

*ç•™ä¸€æ³•ç­–ç•¥(Leave-one-out strategy)*

æµ‹è¯•æ•°æ®ï¼šç”¨æˆ·åºåˆ—çš„æœ€åä¸€ä¸ªé¡¹ç›®

éªŒè¯æ•°æ®(validation data):  å€’æ•°ç¬¬äºŒä¸ªé¡¹ç›®

è®­ç»ƒæ•°æ®ï¼šå‰©ä½™çš„æ•°æ®

> we adopt the leave-one-out strategy, wherein the last item of each user sequence serves as the test data, the items preceding it as validation data, and the remaining data as training data.

*é¢„æµ‹æ—¶å¯¹å…¨ä½“å€™é€‰ç‰©å“é›†åˆè¿›è¡Œæ’åºï¼Œè€Œä¸æ˜¯ä»…å¯¹è´Ÿæ ·æœ¬é‡‡æ ·*

è´Ÿé‡‡æ ·å¯èƒ½ä¼šå¯¼è‡´è¯„ä»·ç»“æœåå·®

<br/>

*å…·ä½“æŒ‡æ ‡ï¼š*

- HR@Kï¼šHit Ratio@K,å‘½ä¸­ç‡ï¼Œæµ‹è¯•ç‰©å“æ˜¯å¦å‡ºç°åœ¨é¢„æµ‹ç»“æœçš„å‰Kä½ï¼Œå­˜åœ¨åˆ™è®¡1ï¼Œå¦åˆ™è®¡0ã€‚åæ˜ â€œæ˜¯å¦æ¨èæˆåŠŸâ€ã€‚
- NDCG@K: Normalized Discounted Cumulative Gain@K,å½’ä¸€åŒ–æŠ˜æŸç´¯è®¡å¢ç›Šï¼Œè€ƒè™‘æµ‹è¯•ç‰©å“åœ¨æ¨èåˆ—è¡¨ä¸­çš„æ’åä½ç½®ï¼Œæ’åè¶Šé å‰å¾—åˆ†è¶Šé«˜ã€‚ååº”â€œæ¨èè´¨é‡â€ã€‚

------

### æ¶ˆèå®éªŒ(Ablation Study)

æ³¨ï¼šæ¶ˆèç ”ç©¶é€šå¸¸æ˜¯æŒ‡é€šè¿‡é€æ­¥ç§»é™¤æˆ–ä¿®æ”¹æ¨¡å‹ä¸­çš„æŸäº›ç»„ä»¶ï¼Œæ¥è§‚å¯Ÿè¿™äº›å˜åŒ–å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä»è€Œç†è§£å„ä¸ªç»„ä»¶çš„ä½œç”¨ã€‚

1. **RP-Fix**: å›ºå®šæ¬¡æ•°ï¼Œæµ‹è¯•1ã€2ã€3æ¬¡ï¼Œå–æœ€å¥½ç»“æœ
2. **RP-Max**ï¼šå¡«å……ç›´è‡³å‰©ä½™ç©ºé—´ä¸å……è¶³
3. **RP(0,Max)**ï¼šæ¯æ¬¡å¡«å……éšæœºé€‰æ‹©0åˆ°æœ€å¤§æ¬¡æ•°
4. **RP(1,Max)**ï¼šæ¯æ¬¡å¡«å……éšæœºé€‰æ‹©1åˆ°æœ€å¤§æ¬¡æ•°

3,4è¡¨ç°è¾ƒå¥½ï¼Œ1,2æå‡æœ‰é™ç”šè‡³å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™

ä¸”4æ›´å¥½ï¼Œè¯´æ˜è‡³å°‘å¡«å……ä¸€æ¬¡æ˜¯å¿…è¦çš„ã€‚

<br/>

*æ˜¯å¦å¡«å……0ï¼Ÿ*

ä¸æ¨èæ¨¡å‹çš„ç±»å‹ç›¸å…³ï¼šRNNä¸åŠ ï¼ŒTransformeråŠ 

æ¨æµ‹ï¼šTransformerä¸ºåŸºç¡€çš„æ¨¡å‹çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶éœ€è¦è€ƒè™‘æ¯ä¸ªå†å²äº¤äº’çš„å½±å“ï¼Œ0å¯èƒ½å‡å°‘â€œç”¨å¤´éƒ¨é¢„æµ‹å°¾éƒ¨â€çš„è´Ÿé¢å½±å“ã€‚

> The self-attention module of Transformer-based models pays attention to the effect of each historical interaction on the following action, so the negative effect of "predicting the tail with the head" can be minimized by adding the delimiter *0*.

------

