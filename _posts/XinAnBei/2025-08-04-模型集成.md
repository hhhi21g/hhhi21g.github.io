---
layout: post

title: 模型集成 —— LightGBM及相关方法介绍

date: 2025-07-31 13:37:23 +0900

categories: [信安杯]
---

### 1. Gradient Boost(梯度提升)

> 讲解视频：https://youtu.be/3CC4N4z3GJc?si=MTAW7mrh7sNhzRbO

与AdaBoost的对比：

- AdaBoost初始时即有stump（树桩），但也只有树桩；
- Gradient Boost(for Regression)初始时只有一个点，为连续值的均值；对于树来说比AdaBoost的树桩大，可以限制**最大叶子结点个数**，通常为**8到32**。

#### Gradient Boost For Regression

<p>
    <img src="https://hhhi21g.github.io/assets/img/xinan/x9.png" alt="alt text" style="zoom:50%;" />
</p>

- 先计算连续值的均值，再计算伪残差：如上图，先计算Weight的均值，再逐一相减；

  <p>
      <img src="https://hhhi21g.github.io/assets/img/xinan/x10.png" alt="alt text" style="zoom:50%;" />
  </p>

- 建立一棵树，由Height, Favorite Color, Gender 预测 Residual;（限制最大叶子结点数目为4）；

  <p>
      <img src="https://hhhi21g.github.io/assets/img/xinan/x11.png" alt="alt text" style="zoom:50%;" />
  </p>

- 最终到同一叶子结点的数据，在上图中即第1、3叶子，对数值取均值，(-14.2 - 15.2)/2 = -14.7, (1.8 + 5.8)/2 = 3.8;

  <p>
      <img src="https://hhhi21g.github.io/assets/img/xinan/x12.png" alt="alt text" style="zoom:50%;" />
  </p>

- 根据其他特征，找到树中对应的叶子结点，用初始树桩值与该叶子结点值相加即为预测值。

  <p>
      <img src="https://hhhi21g.github.io/assets/img/xinan/x13.png" alt="alt text" style="zoom:50%;" />
  </p>

- **问题：拟合的太完美了？ ——  使用学习率**

  <p>
      <img src="https://hhhi21g.github.io/assets/img/xinan/x14.png" alt="alt text" style="zoom:50%;" />
  </p>

- 重复上述步骤：计算每个数据的根据树得到的值，再次与原始值做差，得到新残差；

  <p>
      <img src="https://hhhi21g.github.io/assets/img/xinan/x14.png" alt="alt text" style="zoom:50%;" />
  </p>

- 再次计算时，需要将两个树都计算进来；

  