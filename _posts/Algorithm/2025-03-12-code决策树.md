---
layout: post

title: Code04-决策树

date: 2025-03-12 11:13:23 +0900

categories: [Code]
---

### Code04-决策树

#### kaggle: Titanic-Machine Learning from Disaster

**1. 加载数据:**

```python
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv("test.csv")
```

**2. 计算每一列的缺失数据数：**

```python
print(train_data.isnull().sum())

print(test_data.isnull().sum())
```

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/DTree/d0.png" alt="alt text" style="zoom:50%;" />
    <img src="https://hhhi21g.github.io/public/img/DTree/d1.png" alt="alt text" style="zoom:50%;" />
</p>

**3. 填充缺失数据：**

```python
# 用中位数median填充Age列的缺失值
# inplace = True使操作直接修改train_data数据框，而不是返回一个新的数据框
train_data['Age'].fillna(train_data['Age'].median(),inplace=True)

# 计算Embark列的众数，并取第一个众数[0]
train_data['Embarked'].fillna(train_data['Embarked'].mode()[0],inplace=True)

# 删除Cabin列，axis=1表示删除列，0表示删除行
train_data.drop('Cabin',axis=1,inplace=True)
```

Age使用中位数：连续数值变量，使用中位数比均值更稳健，避免受极端值影响；

Embark使用众数：类别变量，使用最常见的值填充更合理

```python
test_data['Age'].fillna(test_data['Age'].median(),inplace=True)
test_data['Fare'].fillna(test_data['Fare'].median(),inplace=True)
```

**4. 数据数字化：**

根据传入的字典，将原始值替换为对应的映射值

```python
train_data['Sex'] = train_data['Sex'].map({'male':0,'female':1})
train_data['Embarked'] = train_data['Embarked'].map({'C':0,'Q':1,'S':2})

test_data['Sex'] = test_data['Sex'].map({'male':0,'female':1})
test_data['Embarked'] = test_data['Embarked'].map({'C':0,'Q':1,'S':2})
```

**5. 从训练数据中选择特征和目标变量：**

```python
features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']
# 从数据框中提取特征列
X = train_data[features]
y = train_data['Survived']
```

**6. 划分训练集和测试集：**

这里取0.2为测试集；random_state用于控制数据集划分的随机性，保证每次运行代码时得到相同的训练集和测试集

```python
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)
```

**7. 使用决策树分类器：**

- random_state保证每次运行时，决策树的结构相同：

  ```python
  dt_classifier = DecisionTreeClassifier(random_state=42)
  ```

- 使用X_train, y_train训练模型：

  ```python
  dt_classifier.fit(X_train,y_train)
  ```

- 对测试数据X_test进行预测，得到模型的预测结果y_pred

  ```python
  y_pred = dt_classifier.predict(X_test)
  ```

- 计算结果的准确率：

  ```python
  accuracy = accuracy_score(y_test,y_pred)
  print(f'准确率: {accuracy:.4f}')
  ```

  > 准确率: 0.7821

**8. 生成分类模型的评估报告：**

```python
print(classification_report(y_test,y_pred))
```

**9. 生成并绘制混淆矩阵:**

```python
conf_matrix = confusion_matrix(y_test,y_pred)

# annot=True:在热力图单元格上显示数值;
# fmt='d':整数格式；
# cmap='Blues':设定热力图的颜色风格，这里为从浅蓝到深蓝的颜色梯度，颜色越深表示数值越大；
sns.heatmap(conf_matrix,annot=True,fmt='d',cmap='Blues',xticklabels=['Dead','Survived'],yticklabels=['Dead','Survived'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
```

- `conf_matrix[i][j]`表示真实类别为i，但模型预测为j的样本数；

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/DTree/d2.png" alt="alt text" style="zoom:70%;" />
</p>

**10. 预测数据并输出csv文件**

```python
x_test_data = test_data[features]
test_predictions = dt_classifier.predict(x_test_data)

submission = pd.DataFrame({
    'PassengerId':test_data['PassengerId'],
    'Survived':test_predictions
})

# index=False确保不会额外保存Pandas自动生成的索引列
submission.to_csv('submission.csv',index=False)
```

