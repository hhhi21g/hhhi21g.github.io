---
layout: post

title: 机器学习第8讲——贝叶斯方法

date: 2025-05-31 17:49:23 +0900

categories: [DeepLearning]
---

- [贝叶斯方法](#贝叶斯方法)
  - [背景知识](#背景知识)
    - [贝叶斯分类](#贝叶斯分类)
    - [后验概率](#后验概率)
    - [贝叶斯公式](#贝叶斯公式)
  - [分类准则](#分类准则)
    - [最大后验概率分类准则](#最大后验概率分类准则)
    - [最小错误概率分类准则](#最小错误概率分类准则)
    - [最小风险分类准则](#最小风险分类准则)
  - [例题](#例题)
- [分类器](#分类器)
  - [分类器的优化问题](#分类器的优化问题)
  - [最小平均错误概率分类器](#最小平均错误概率分类器)
  - [最小平均风险分类器](#最小平均风险分类器)
  - [例题PPT12](#例题ppt12)
- [朴素贝叶斯分类器(naive Bayes classifier)](#朴素贝叶斯分类器naive-bayes-classifier)
  - [朴素](#朴素)
  - [算法流程](#算法流程)
  - [例题PPT42](#例题ppt42)
  - [拉普拉斯平滑](#拉普拉斯平滑)
  - [优缺点](#优缺点)
### 贝叶斯方法

#### 背景知识

##### 贝叶斯分类

一类分类算法的总称，这类算法均以贝叶斯定理为基础

##### 先验概率

根据以往经验和分析得到的概率。

使用P(Y)代表**没有训练数据前**假设Y拥有的初始概率

##### 后验概率

根据已经发生的事件来分析得到的概率。

以P(Y|X)代表假设X成立的情况下观察到Y数据的概率，其反映了在**看到训练数据X后**Y成立的置信度。

##### 贝叶斯公式

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d249.png" alt="alt text" style="zoom:60%;" />
</p>

朴素贝叶斯法是典型的生成学习算法。

具体来说：**利用训练数据学习P(X|Y)和P(Y)的估计**，得到联合概率分布

****

#### 分类准则

##### 最大后验概率分类准则

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d250.png" alt="alt text" style="zoom:60%;" />
</p>

- 对于样本x，给其分配使其后验概率最大的一类

**但是后验概率未知**

根据贝叶斯公式：

只需要比较分子p(x|w1)p(w1)和p(x|w2)p(w2)

##### 最小错误概率分类准则

将样本x错误分类的概率：

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d251.png" alt="alt text" style="zoom:60%;" />
</p>

##### 最小风险分类准则

风险矩阵：

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d252.png" alt="alt text" style="zoom:60%;" />
</p>

- 不同的决策可能有不同的风险值；
- 即使决策正确，对应的风险值也不一定为0；
- 在习题中把对角线，即决策正确的点，风险设置为0，体现最小风险。

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d253.png" alt="alt text" style="zoom:60%;" />
</p>

****

#### 例题

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d254.png" alt="alt text" style="zoom:60%;" />
</p>

****

### 分类器

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d255.png" alt="alt text" style="zoom:60%;" />
</p>

#### 分类器的优化问题

- L(h;X,Y): 目标函数
- h(·): 数学形式为一个函数，很难直接优化；
  - 给其**限定为某种特定的函数形式**，如，多阶多项式，阶跃函数等；
  - 优化过程不会改变函数形式，仅对其中的参数进行优化；
  - h(·)的所有函数形式为“假设空间”，参数值定义具体的假设

#### 最小平均错误概率分类器

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d256.png" alt="alt text" style="zoom:60%;" />
</p>

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d257.png" alt="alt text" style="zoom:60%;" />
</p>

> 注意：这里纵轴反映的是后验概率大小，1-左部分积分才是错误概率

#### 最小平均风险分类器

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d258.png" alt="alt text" style="zoom:60%;" />
</p>

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d259.png" alt="alt text" style="zoom:60%;" />
</p>

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d260.png" alt="alt text" style="zoom:60%;" />
</p>

#### 例题PPT12

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d261.png" alt="alt text" style="zoom:60%;" />
</p>

****

### 朴素贝叶斯分类器(naive Bayes classifier)

监督学习方法分为：

- 判别方法(Discriminative approach);
- **生成方法**(Generative approach): 由训练数据学习联合概率分布P(X,Y),然后求得后验概率分布。 

**朴素贝叶斯法是典型的生成学习方法。**

#### 朴素

假设所有特征/属性**在给定类别下相互独立**(attribute conditional independence assumption)。

#### 算法流程

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d262.png" alt="alt text" style="zoom:60%;" />
</p>

对所有类别来说P(x)相同，且P(x)与类别c无关，分类可以不考虑。因此**贝叶斯判定准则**有：

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d263.png" alt="alt text" style="zoom:60%;" />
</p>

若有充足的独立同分布样本，则**先验概率**：

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d264.png" alt="alt text" style="zoom:60%;" />
</p>

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d265.png" alt="alt text" style="zoom:60%;" />
</p>

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d266.png" alt="alt text" style="zoom:60%;" />
</p>

> 注：最后一步去分母，可从等式前面得出，分母与分类无关

#### 例题PPT42

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d267.png" alt="alt text" style="zoom:60%;" />
</p>

****

#### 拉普拉斯平滑

一种用于平滑分类数据的技术。引入拉普拉斯平滑法来解决零概率问题。通过应用此方法，先验概率和条件概率可以写为：

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d268.png" alt="alt text" style="zoom:60%;" />
</p>

- K：类别数量；
- A：a<sub>j</sub>中不同值的数量
- λ：通常为1

**加入拉普拉斯平滑后，避免了出现概率为0的情况，又保证了每个值都在0到1的范围内，又保证了最终和为1的概率性质。**

****

#### 优缺点

<p align="center">
    <img src="https://hhhi21g.github.io/public/img/deepLearning/d269.png" alt="alt text" style="zoom:60%;" />
</p>

****